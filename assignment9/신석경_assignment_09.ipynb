{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "신석경_assignment_09",
      "provenance": [],
      "authorship_tag": "ABX9TyMYAWP9/gQ+Bnl4QVAhMvjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiku100/2020-2-machine-running-proejct/blob/master/assignment9/%EC%8B%A0%EC%84%9D%EA%B2%BD_assignment_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gzdXwFJz0KJ"
      },
      "source": [
        "# **Classification for Multiple Categories using Pytorch**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_C7Cujjz4ff"
      },
      "source": [
        "# 1. Import library\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtlbKT3Izgre"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC9KWsHg7lTJ",
        "outputId": "d88244ba-9eba-46fb-d2b3-e0dbba2248e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBCurPvD3NoM"
      },
      "source": [
        "# 2. Load Data\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPY4_F790FTB"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,),(0.3081,)),  # mean value = 0.1307, standard deviation value = 0.3081\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlkn2L_m3TGH"
      },
      "source": [
        "data_path = './MNIST'\n",
        "\n",
        "training_set = datasets.MNIST(root = data_path, train= True, download=True, transform= transform)\n",
        "testing_set = datasets.MNIST(root = data_path, train= False, download=True, transform= transform)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUj2JTgY4r4c"
      },
      "source": [
        "batch_32 = 32\n",
        "batch_64 = 64\n",
        "batch_128 = 128\n",
        "learning_rate_value = 1e-2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkgCtS3b3giF"
      },
      "source": [
        "train_loader_32 = DataLoader(dataset = training_set, batch_size = batch_32, shuffle = True) ## batch size 32 짜리 train loader 생성\n",
        "test_loader_32 = DataLoader(dataset = testing_set, batch_size = batch_32, shuffle = True) ## batch size 32 짜리 test loader 생성\n",
        "\n",
        "train_loader_64 = DataLoader(dataset = training_set, batch_size = batch_64, shuffle = True) ## batch size 64 짜리 train loader 생성\n",
        "test_loader_64 = DataLoader(dataset = testing_set, batch_size = batch_64, shuffle = True) ## batch size 64 짜리 test loader 생성\n",
        "\n",
        "train_loader_128 = DataLoader(dataset = training_set, batch_size = batch_128, shuffle = True) ## batch size 128 짜리 train loader 생성\n",
        "test_loader_128 = DataLoader(dataset = testing_set, batch_size = batch_128, shuffle = True) ## batch size 128 짜리 test loader 생성"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnv1UBAk3qtB",
        "outputId": "41135a94-1626-49e6-d79f-ab22301280a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "for X, Y in train_loader_32:\n",
        "  plt.imshow(X[0][0].numpy())\n",
        "  print(f\"Target: {Y[0]}\")\n",
        "  break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCsB9Pdk6zd7"
      },
      "source": [
        "# 3. Define Model\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cUHqcW25etQ"
      },
      "source": [
        "class classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(classification, self).__init__()\n",
        "        \n",
        "        # construct layers for a neural network\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28, out_features=20*20),\n",
        "            nn.Sigmoid(),\n",
        "        ) \n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(in_features=20*20, out_features=10*10),\n",
        "            nn.Sigmoid(),\n",
        "        ) \n",
        "        self.classifier3 = nn.Sequential(\n",
        "            nn.Linear(in_features=10*10, out_features=10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        ) \n",
        "        \n",
        "        \n",
        "    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n",
        "        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n",
        "        x = self.classifier1(x)                # [batchSize, 20*20]\n",
        "        x = self.classifier2(x)                # [batchSize, 10*10]\n",
        "        out = self.classifier3(x)              # [batchSize, 10]\n",
        "        \n",
        "        return out\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWYQ30d37dwC"
      },
      "source": [
        "classifier_32 = classification().to(device)\n",
        "classifier_64 = classification().to(device)\n",
        "classifier_128 = classification().to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GpzWr1V64wc"
      },
      "source": [
        "## Loss function\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Optimization\n",
        "optimizer = torch.optim.SGD(classifier_32.parameters(), lr=learning_rate_value)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsNWP3Wk8Siq"
      },
      "source": [
        "# 4. Training\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_QSSPkC7sCr"
      },
      "source": [
        "training_epochs = 60\n",
        "total_batch_32 = len(train_loader_32)\n",
        "total_batch_64 = len(train_loader_64)\n",
        "total_batch_128 = len(train_loader_128)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl5FuVgt8_LF"
      },
      "source": [
        "def training(model, loss, optim, training_epochs, total_batch, train_loader, test_loader):\n",
        "  L_iters = []\n",
        "  accuracy = []\n",
        "  for epoch in range(training_epochs):\n",
        "    total_cost_train = 0\n",
        "    total_cost_test = 0\n",
        "    for (X, Y), (X_test, Y_test) in zip(train_loader, test_loader):\n",
        "      X = X.to(device)\n",
        "      Y = Y.to(device)\n",
        "\n",
        "      optim.zero_grad()\n",
        "      train_pred = model(X)\n",
        "      cost = loss(train_pred, Y)\n",
        "      cost.backward()\n",
        "      optim.step()\n",
        "      total_cost_train += cost\n",
        "\n",
        "      with torch.no_grad():\n",
        "        X_test = X_test.to(device)\n",
        "        Y_test = Y_test.to(device)\n",
        "        test_pred = model(X_test)\n",
        "        cost_test = loss(test_pred, Y_test)\n",
        "        total_cost_test += cost_test\n",
        "\n",
        "    avg_cost_train = total_cost_train / total_batch\n",
        "    avg_cost_test = total_cost_test / total_batch\n",
        "    L_iters.append(avg_cost_train)\n",
        "    print(\"Epoch: %02d Training Loss: %.9f Testing Loss: %.9f\" %((epoch + 1),avg_cost_train, avg_cost_test))\n",
        "  return L_iters, accuracy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOfKPriA84jq",
        "outputId": "3574aa15-5cb6-4186-bf68-501fa591d5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "L_32, A_32 = training(classifier_32, criterion, optimizer, training_epochs, total_batch_32, train_loader_32, test_loader_32)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 Training Loss: 0.334660739 Testing Loss: 0.333807379\n",
            "Epoch: 02 Training Loss: 0.301364094 Testing Loss: 0.300448388\n",
            "Epoch: 03 Training Loss: 0.264837235 Testing Loss: 0.261980504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bc488e19c742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_batch_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader_32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-7bb829a249cc>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, loss, optim, training_epochs, total_batch, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-5b5caeb0162f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# [batchSize, 28*28]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# [batchSize, 20*20]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# [batchSize, 10*10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# [batchSize, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzn6YyGw9ULY"
      },
      "source": [
        "for (X, Y), (X_test, Y_test) in zip(train_loader_32, test_loader_32):\n",
        "  print(X[0][0])\n",
        "  print(Y[0])\n",
        "  print(X_test[0][0])\n",
        "  print(Y_test[0])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X-MPa8z9uci"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}