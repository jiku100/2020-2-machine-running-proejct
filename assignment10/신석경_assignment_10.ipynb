{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "신석경_assignment_10",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEV3jB5muFZpr+wCfSEZYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiku100/2020-2-machine-running-proejct/blob/master/assignment10/%EC%8B%A0%EC%84%9D%EA%B2%BD_assignment_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gzdXwFJz0KJ"
      },
      "source": [
        "# **Classification for Multiple Categories using Pytorch for best accuracy**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_C7Cujjz4ff"
      },
      "source": [
        "# 1. Import library\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtlbKT3Izgre"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC9KWsHg7lTJ",
        "outputId": "93019da1-2f06-475e-b2d4-f008d39c7bf6"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBCurPvD3NoM"
      },
      "source": [
        "# 2. Preprocessing Data\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tVba13YD-s9"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "        transforms.ToTensor(), \n",
        "        transforms.Normalize((0.5,), (1.0,))                      # 이미지를 텐서로 변형합니다.\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(), \n",
        "        transforms.Normalize((0.5,), (1.0,))             \n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uNdu0HqJEQv"
      },
      "source": [
        "data_path = './MNIST'\n",
        "\n",
        "data_test   = datasets.MNIST(root = data_path, train= True, download=True, transform= transform_test)\n",
        "data_train  = datasets.MNIST(root = data_path, train= False, download=True, transform= transform_train)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "8SJcK-t2D3Bp",
        "outputId": "0b52efe8-2219-4e75-daf0-333a1c166ab1"
      },
      "source": [
        "one_image, label = data_train[0]\n",
        "print(\"type of one image\", type(one_image))\n",
        "print(\"size of one image : \", one_image.shape)\n",
        "plt.imshow(one_image.squeeze().numpy(), cmap='gray')\n",
        "print(\"type of label : \", type(label))\n",
        "print(\"label : \", label)\n",
        "print(np.max(data_train.train_data[0].view(-1).numpy()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type of one image <class 'torch.Tensor'>\n",
            "size of one image :  torch.Size([1, 28, 28])\n",
            "type of label :  <class 'int'>\n",
            "label :  7\n",
            "255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUj2JTgY4r4c"
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 100\n",
        "batch_size = 32\n",
        "drop_prob = 0.4"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkgCtS3b3giF"
      },
      "source": [
        "train_loader = DataLoader(dataset = data_train, batch_size = batch_size, num_workers = 2, shuffle = True) ## batch size 32 짜리 train loader 생성\n",
        "test_loader = DataLoader(dataset = data_test, batch_size = batch_size, num_workers = 2, shuffle = True) ## batch size 32 짜리 test loader 생성"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCsB9Pdk6zd7"
      },
      "source": [
        "# 3. Define Model\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cUHqcW25etQ"
      },
      "source": [
        "class classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(classification, self).__init__()\n",
        "        \n",
        "        # construct layers for a neural network\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28, out_features=20*20, bias = True),\n",
        "            nn.BatchNorm1d(20*20),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=drop_prob)\n",
        "        ) \n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(in_features=20*20, out_features=10*10, bias = True),\n",
        "            nn.BatchNorm1d(10*10),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=drop_prob)\n",
        "        ) \n",
        "        self.classifier3 = nn.Sequential(\n",
        "            nn.Linear(in_features=100, out_features=10, bias = True),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        ) \n",
        "\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "            init.kaiming_normal_(m.weight.data) # Kaming He Initialization\n",
        "            m.bias.data.fill_(0)                # 편차를 0으로 초기화 \n",
        "\n",
        "    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n",
        "        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n",
        "        x = self.classifier1(x)                # [batchSize, 20*20]\n",
        "        x = self.classifier2(x)                # [batchSize, 10*10]\n",
        "        out = self.classifier3(x)              # [batchSize, 10]\n",
        "        \n",
        "        return out\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWYQ30d37dwC"
      },
      "source": [
        "model = classification().to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GpzWr1V64wc"
      },
      "source": [
        "criterion = nn.NLLLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.1, last_epoch=-1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsNWP3Wk8Siq"
      },
      "source": [
        "# 4. Training\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_QSSPkC7sCr"
      },
      "source": [
        "total_batch= len(train_loader)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_SeUrHB5gLH",
        "outputId": "8ab9c3f0-cd17-495f-f1a2-f938019d60ef"
      },
      "source": [
        "print(total_batch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaJMZ8TvcglJ"
      },
      "source": [
        "def accuracy(log_pred, y_true):\n",
        "    y_pred = torch.argmax(log_pred, dim=1)\n",
        "    return (y_pred == y_true).to(torch.float).mean()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl5FuVgt8_LF"
      },
      "source": [
        "def training(model, loss, optim, training_epochs, train_loader, test_loader):\n",
        "  L_iters_train = []\n",
        "  accuracy_train = []\n",
        "  L_iters_test = []\n",
        "  accuracy_test = []\n",
        "  for epoch in range(training_epochs):\n",
        "    total_cost_train = 0\n",
        "    total_cost_test = 0\n",
        "    total_acc_train = 0\n",
        "    total_acc_test = 0\n",
        "    model.train()\n",
        "    for X, Y in train_loader:\n",
        "      X = X.to(device)\n",
        "      Y = Y.to(device)\n",
        "\n",
        "      optim.zero_grad()\n",
        "      train_pred = model(X)\n",
        "      cost = loss(train_pred, Y)\n",
        "      cost.backward()\n",
        "      optim.step()\n",
        "\n",
        "      total_cost_train += cost\n",
        "      total_acc_train += accuracy(train_pred, Y)\n",
        "      \n",
        "    avg_cost_train = total_cost_train / len(train_loader)\n",
        "    avg_acc_train = total_acc_train / len(train_loader)\n",
        "\n",
        "    L_iters_train.append(avg_cost_train)\n",
        "    accuracy_train.append(avg_acc_train)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for X_test, Y_test in test_loader:\n",
        "        X_test = X_test.to(device)\n",
        "        Y_test = Y_test.to(device)\n",
        "        test_pred = model(X_test)\n",
        "        cost_test = loss(test_pred, Y_test)\n",
        "        total_cost_test += cost_test\n",
        "        total_acc_test += accuracy(test_pred, Y_test)\n",
        "      avg_cost_test = total_cost_test / len(test_loader)\n",
        "      avg_acc_test = total_acc_test / len(test_loader)\n",
        "    \n",
        "      accuracy_test.append(avg_acc_test)\n",
        "      L_iters_test.append(avg_cost_test)\n",
        "\n",
        "    print(\"Epoch: %02d Training Loss: %.9f Testing Loss: %.9f  Training Acc: %.9f Testing Acc: %.9f\" %((epoch + 1),avg_cost_train, avg_cost_test, avg_acc_train, avg_acc_test))\n",
        "  return L_iters_train, accuracy_train, L_iters_test, accuracy_test"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOfKPriA84jq",
        "outputId": "08743a50-bc1c-4732-8440-3a8e764a9ab6"
      },
      "source": [
        "L_train, A_train, L_test, A_test = training(model, criterion, optimizer, training_epochs, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 Training Loss: 1.060441017 Testing Loss: 0.450563222  Training Acc: 0.651257992 Testing Acc: 0.868066669\n",
            "Epoch: 02 Training Loss: 0.659987807 Testing Loss: 0.340691954  Training Acc: 0.792831481 Testing Acc: 0.895983338\n",
            "Epoch: 03 Training Loss: 0.561349511 Testing Loss: 0.304287672  Training Acc: 0.821984828 Testing Acc: 0.908500016\n",
            "Epoch: 04 Training Loss: 0.515611589 Testing Loss: 0.268975794  Training Acc: 0.837559879 Testing Acc: 0.917883337\n",
            "Epoch: 05 Training Loss: 0.467359006 Testing Loss: 0.236277789  Training Acc: 0.853933692 Testing Acc: 0.930033326\n",
            "Epoch: 06 Training Loss: 0.421280205 Testing Loss: 0.229185745  Training Acc: 0.865415335 Testing Acc: 0.930066705\n",
            "Epoch: 07 Training Loss: 0.406506658 Testing Loss: 0.216114298  Training Acc: 0.867312312 Testing Acc: 0.933533370\n",
            "Epoch: 08 Training Loss: 0.401773214 Testing Loss: 0.204531446  Training Acc: 0.871006370 Testing Acc: 0.939000010\n",
            "Epoch: 09 Training Loss: 0.371858120 Testing Loss: 0.197647646  Training Acc: 0.882188499 Testing Acc: 0.941266656\n",
            "Epoch: 10 Training Loss: 0.356756508 Testing Loss: 0.187863499  Training Acc: 0.886481643 Testing Acc: 0.943233371\n",
            "Epoch: 11 Training Loss: 0.343557894 Testing Loss: 0.187363654  Training Acc: 0.889776349 Testing Acc: 0.942783356\n",
            "Epoch: 12 Training Loss: 0.339545101 Testing Loss: 0.173438624  Training Acc: 0.893170893 Testing Acc: 0.946683347\n",
            "Epoch: 13 Training Loss: 0.332422078 Testing Loss: 0.168741837  Training Acc: 0.892971218 Testing Acc: 0.949116707\n",
            "Epoch: 14 Training Loss: 0.311115116 Testing Loss: 0.165345415  Training Acc: 0.902356207 Testing Acc: 0.949283361\n",
            "Epoch: 15 Training Loss: 0.314631045 Testing Loss: 0.155252039  Training Acc: 0.903753996 Testing Acc: 0.953150034\n",
            "Epoch: 16 Training Loss: 0.304822892 Testing Loss: 0.152781352  Training Acc: 0.901357830 Testing Acc: 0.954200029\n",
            "Epoch: 17 Training Loss: 0.292161942 Testing Loss: 0.156615838  Training Acc: 0.906948864 Testing Acc: 0.953249991\n",
            "Epoch: 18 Training Loss: 0.294073969 Testing Loss: 0.150461599  Training Acc: 0.906549513 Testing Acc: 0.953783333\n",
            "Epoch: 19 Training Loss: 0.281117320 Testing Loss: 0.143222108  Training Acc: 0.912440062 Testing Acc: 0.956200004\n",
            "Epoch: 20 Training Loss: 0.283144116 Testing Loss: 0.139382124  Training Acc: 0.910842657 Testing Acc: 0.958249986\n",
            "Epoch: 21 Training Loss: 0.268456697 Testing Loss: 0.142540917  Training Acc: 0.919229209 Testing Acc: 0.956083357\n",
            "Epoch: 22 Training Loss: 0.271167696 Testing Loss: 0.142540351  Training Acc: 0.913937688 Testing Acc: 0.957016706\n",
            "Epoch: 23 Training Loss: 0.257002383 Testing Loss: 0.134823218  Training Acc: 0.919428885 Testing Acc: 0.958999991\n",
            "Epoch: 24 Training Loss: 0.252107799 Testing Loss: 0.139360696  Training Acc: 0.921126187 Testing Acc: 0.958216667\n",
            "Epoch: 25 Training Loss: 0.250488847 Testing Loss: 0.135496423  Training Acc: 0.920027912 Testing Acc: 0.959583342\n",
            "Epoch: 26 Training Loss: 0.249696091 Testing Loss: 0.136922017  Training Acc: 0.920726836 Testing Acc: 0.958683372\n",
            "Epoch: 27 Training Loss: 0.244381294 Testing Loss: 0.129090339  Training Acc: 0.922324240 Testing Acc: 0.960833371\n",
            "Epoch: 28 Training Loss: 0.249511003 Testing Loss: 0.134493664  Training Acc: 0.920626998 Testing Acc: 0.958416700\n",
            "Epoch: 29 Training Loss: 0.241964221 Testing Loss: 0.130396843  Training Acc: 0.923821867 Testing Acc: 0.960449994\n",
            "Epoch: 30 Training Loss: 0.234331444 Testing Loss: 0.138110176  Training Acc: 0.924720407 Testing Acc: 0.958283365\n",
            "Epoch: 31 Training Loss: 0.229468808 Testing Loss: 0.126345426  Training Acc: 0.924121380 Testing Acc: 0.961833358\n",
            "Epoch: 32 Training Loss: 0.237025008 Testing Loss: 0.129511982  Training Acc: 0.927116573 Testing Acc: 0.960900009\n",
            "Epoch: 33 Training Loss: 0.231093526 Testing Loss: 0.123674914  Training Acc: 0.927915335 Testing Acc: 0.962683320\n",
            "Epoch: 34 Training Loss: 0.221404001 Testing Loss: 0.127822012  Training Acc: 0.928913713 Testing Acc: 0.960516691\n",
            "Epoch: 35 Training Loss: 0.222494110 Testing Loss: 0.121034965  Training Acc: 0.928614199 Testing Acc: 0.963116705\n",
            "Epoch: 36 Training Loss: 0.217060566 Testing Loss: 0.122373722  Training Acc: 0.929512739 Testing Acc: 0.962150037\n",
            "Epoch: 37 Training Loss: 0.225503817 Testing Loss: 0.127146751  Training Acc: 0.929512739 Testing Acc: 0.961149991\n",
            "Epoch: 38 Training Loss: 0.206862152 Testing Loss: 0.127480507  Training Acc: 0.933706045 Testing Acc: 0.961050034\n",
            "Epoch: 39 Training Loss: 0.212320834 Testing Loss: 0.117669128  Training Acc: 0.934804320 Testing Acc: 0.964016676\n",
            "Epoch: 40 Training Loss: 0.216135934 Testing Loss: 0.116183691  Training Acc: 0.931609392 Testing Acc: 0.964416683\n",
            "Epoch: 41 Training Loss: 0.210331038 Testing Loss: 0.115863234  Training Acc: 0.931809068 Testing Acc: 0.964433372\n",
            "Epoch: 42 Training Loss: 0.204474688 Testing Loss: 0.118326284  Training Acc: 0.934704483 Testing Acc: 0.964233339\n",
            "Epoch: 43 Training Loss: 0.199921757 Testing Loss: 0.117765747  Training Acc: 0.937000811 Testing Acc: 0.964049995\n",
            "Epoch: 44 Training Loss: 0.199071392 Testing Loss: 0.118687160  Training Acc: 0.938198864 Testing Acc: 0.963833332\n",
            "Epoch: 45 Training Loss: 0.200377211 Testing Loss: 0.110345818  Training Acc: 0.936501563 Testing Acc: 0.966499984\n",
            "Epoch: 46 Training Loss: 0.190743044 Testing Loss: 0.111328058  Training Acc: 0.938897729 Testing Acc: 0.966149986\n",
            "Epoch: 47 Training Loss: 0.198830098 Testing Loss: 0.108545870  Training Acc: 0.937300324 Testing Acc: 0.966949999\n",
            "Epoch: 48 Training Loss: 0.210014343 Testing Loss: 0.113634080  Training Acc: 0.934804320 Testing Acc: 0.964866698\n",
            "Epoch: 49 Training Loss: 0.191118687 Testing Loss: 0.110551253  Training Acc: 0.939197242 Testing Acc: 0.966933370\n",
            "Epoch: 50 Training Loss: 0.200034007 Testing Loss: 0.115989625  Training Acc: 0.936900914 Testing Acc: 0.964416683\n",
            "Epoch: 51 Training Loss: 0.177711844 Testing Loss: 0.115943156  Training Acc: 0.942292333 Testing Acc: 0.965333343\n",
            "Epoch: 52 Training Loss: 0.189363152 Testing Loss: 0.111066617  Training Acc: 0.942791522 Testing Acc: 0.966149986\n",
            "Epoch: 53 Training Loss: 0.200780243 Testing Loss: 0.107875593  Training Acc: 0.936701238 Testing Acc: 0.966983318\n",
            "Epoch: 54 Training Loss: 0.189546347 Testing Loss: 0.115361586  Training Acc: 0.938198864 Testing Acc: 0.965333343\n",
            "Epoch: 55 Training Loss: 0.193885207 Testing Loss: 0.111427195  Training Acc: 0.940894544 Testing Acc: 0.965783358\n",
            "Epoch: 56 Training Loss: 0.191551760 Testing Loss: 0.113170139  Training Acc: 0.943290710 Testing Acc: 0.966000021\n",
            "Epoch: 57 Training Loss: 0.173699036 Testing Loss: 0.112812161  Training Acc: 0.944688499 Testing Acc: 0.965550005\n",
            "Epoch: 58 Training Loss: 0.179932043 Testing Loss: 0.109812543  Training Acc: 0.944089413 Testing Acc: 0.966883361\n",
            "Epoch: 59 Training Loss: 0.179243073 Testing Loss: 0.103707209  Training Acc: 0.942192495 Testing Acc: 0.969033360\n",
            "Epoch: 60 Training Loss: 0.179590940 Testing Loss: 0.107678741  Training Acc: 0.943091035 Testing Acc: 0.967333317\n",
            "Epoch: 61 Training Loss: 0.176403463 Testing Loss: 0.109656282  Training Acc: 0.941194057 Testing Acc: 0.967066705\n",
            "Epoch: 62 Training Loss: 0.181991577 Testing Loss: 0.108688705  Training Acc: 0.941793144 Testing Acc: 0.967100024\n",
            "Epoch: 63 Training Loss: 0.180283278 Testing Loss: 0.109953463  Training Acc: 0.942192495 Testing Acc: 0.966566682\n",
            "Epoch: 64 Training Loss: 0.174011022 Testing Loss: 0.115988970  Training Acc: 0.941892982 Testing Acc: 0.965000033\n",
            "Epoch: 65 Training Loss: 0.172211498 Testing Loss: 0.108868673  Training Acc: 0.945287526 Testing Acc: 0.966883361\n",
            "Epoch: 66 Training Loss: 0.183625713 Testing Loss: 0.108955026  Training Acc: 0.942891359 Testing Acc: 0.966899991\n",
            "Epoch: 67 Training Loss: 0.176062003 Testing Loss: 0.109226115  Training Acc: 0.940794706 Testing Acc: 0.968033373\n",
            "Epoch: 68 Training Loss: 0.172587827 Testing Loss: 0.109538019  Training Acc: 0.946984828 Testing Acc: 0.968283355\n",
            "Epoch: 69 Training Loss: 0.171128675 Testing Loss: 0.105275743  Training Acc: 0.943690062 Testing Acc: 0.969099998\n",
            "Epoch: 70 Training Loss: 0.170549124 Testing Loss: 0.111334123  Training Acc: 0.947184503 Testing Acc: 0.966016650\n",
            "Epoch: 71 Training Loss: 0.170293033 Testing Loss: 0.102693729  Training Acc: 0.944888175 Testing Acc: 0.968950033\n",
            "Epoch: 72 Training Loss: 0.172824219 Testing Loss: 0.101565026  Training Acc: 0.946585417 Testing Acc: 0.969099998\n",
            "Epoch: 73 Training Loss: 0.163911462 Testing Loss: 0.100199349  Training Acc: 0.947783530 Testing Acc: 0.969883323\n",
            "Epoch: 74 Training Loss: 0.157614782 Testing Loss: 0.108842202  Training Acc: 0.948881745 Testing Acc: 0.967500031\n",
            "Epoch: 75 Training Loss: 0.169728026 Testing Loss: 0.107203238  Training Acc: 0.944089413 Testing Acc: 0.967599988\n",
            "Epoch: 76 Training Loss: 0.165040195 Testing Loss: 0.104645401  Training Acc: 0.948282719 Testing Acc: 0.969200015\n",
            "Epoch: 77 Training Loss: 0.165030539 Testing Loss: 0.104474887  Training Acc: 0.945387363 Testing Acc: 0.968600035\n",
            "Epoch: 78 Training Loss: 0.167669952 Testing Loss: 0.102011994  Training Acc: 0.945786715 Testing Acc: 0.969166696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzn6YyGw9ULY"
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "plt.plot(L_train, linewidth = 2, c='b', label = \"train\")\n",
        "plt.plot(L_test, linewidth = 2, c='r', label = \"test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl1MuQhtqsg2"
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "plt.plot(A_train, linewidth = 2, c='b', label = \"train\")\n",
        "plt.plot(A_test, linewidth = 2, c='r', label = \"test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4990rRublMpD"
      },
      "source": [
        "print(\"training loss    %.2f\" %(L_train))\n",
        "print(\"testing loss     %.2f\" %(L_test))\n",
        "print(\"training acc    %.2f\" %(A_train))\n",
        "print(\"testing acc     %.2f\" %(A_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4L9RrzOz5xl"
      },
      "source": [
        "# 5. Output\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alN6-n0r0DTO"
      },
      "source": [
        "## 1. Plot the training and testing losses with a batch size of 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t1dSyC1AVe0"
      },
      "source": [
        "## 2. Plot the training and testing accuracies with a batch size of 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px7XRkcnAnc7"
      },
      "source": [
        "## 3. Plot the training and testing losses with a batch size of 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW87VTpwAtMB"
      },
      "source": [
        "## 4. Plot the training and testing accuracies with a batch size of 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl5XI9EVA6QH"
      },
      "source": [
        "## 5. Plot the training and testing losses with a batch size of 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10I91neJBHb1"
      },
      "source": [
        "## 6. Plot the training and testing accuracies with a batch size of 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDI0NljKBNF9"
      },
      "source": [
        "## 7. Print the loss at convergence with different mini-batch sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifTX7c5MCLSf"
      },
      "source": [
        "## 8. Print the accuracy at convergence with different mini-batch sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpgCDaBpCWT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}